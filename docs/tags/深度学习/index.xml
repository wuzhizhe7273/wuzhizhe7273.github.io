<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>深度学习 on Wanderer Fantansy</title>
    <link>https://wuzhizhe7273.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 深度学习 on Wanderer Fantansy</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 16 May 2022 10:16:03 +0800</lastBuildDate><atom:link href="https://wuzhizhe7273.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>深度学习实验2</title>
      <link>https://wuzhizhe7273.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E9%AA%8C2/</link>
      <pubDate>Mon, 16 May 2022 10:16:03 +0800</pubDate>
      
      <guid>https://wuzhizhe7273.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E9%AA%8C2/</guid>
      <description>实验指导  读取猫狗分类数据集 从kaggle在线网站中下载猫狗分类数据集（https://www.kaggle.com/c/dogs-vs-cats/data），这个数据集包含25000张猫狗图像（每个类别都有12500张），大小为543MB（压缩后）。下载数据并解压之后，你需要创建一个新数据集，其中包含三个子集：每个类别各1000个样本的训练集、每个类别各500个样本的验证集和每个类别各500个样本的测试集。 数据预处理 首先，将数据分为“train”文件夹、“test”文件夹、“validation”文件夹；每个文件夹内分别包含以“cat”和“dog”命名的两个文件夹；train文件夹中， cat”和“dog”类别各有1000个样本；test和validation文件夹中，“cat”和“dog”类别各有500个样本。 其次，由于数据以JPEG文件的形式保存在硬盘中，在将数据输入CNN之前，应该将数据格式化为经过预处理的浮点数张量，预处理步骤大致如下：  读取图像文件； 将JPEG文件解码为RGB像素网格； 将这些像素网格转换为浮点数张量； 将像素值（0~255范围内）缩放到[0, 1]区间（正如你所知，神经网络喜欢处理较小的输入值）。 最后，需要将每张图片的大小限定为150*150像素点大小，且将数据按批次（batch）输入模型，批次大小（batch_size）自定义；另外，需要将标签离散化。   构建模型 设计模型卷积层的个数，每一层卷积核的个数，每层的激活函数以及是否含有池化层，最后一层是输出层，它是一个包含两个神经元的softmax层，将返回一个由2个概率值（总和为1）组成的数组。每个概率值表示当前彩色图像属于猫狗中某一个类别的概率。 确定编译参数 对模型进行编译，需要设置以下三个参数：  损失函数：网络如何衡量在训练数据上的性能，即网络如何朝着正确的方向前进。 优化器：基于训练数据和损失函数来更新网络的机制。 评价指标：在训练和测试过程中需要监控的指标包括准确率、精度、召回率等。   模型的训练  将训练数据输入神经网络； 网络学习将图像和标签关联在一起； 将测试数据输入已训练模型，验证预测结果与真实标签是否匹配。    实验内容 给定猫狗分类数据集，自行下载训练集和测试集。要求如下：
 对于测试集数据，完成分类预测，实验精度达到85%以上； 给出每层卷积核的物理解释，阐述其表征意义； 绘制程序流程图（要求用visio制图）； 源代码及必要注释； 总结  报告要求  写出该流程的流程图，以及各个流程快的可视化代码和源代码，以及流程运行过程。 写出实验的心得与体会。  </description>
    </item>
    
    <item>
      <title>深度学习作业1</title>
      <link>https://wuzhizhe7273.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A1/</link>
      <pubDate>Sun, 15 May 2022 15:55:04 +0800</pubDate>
      
      <guid>https://wuzhizhe7273.github.io/p/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BD%9C%E4%B8%9A1/</guid>
      <description>实验要求  能够对样本数据进行归一化处理； 能够设计深度神经网络模型； 能够分析神经网络中层的表征意义； 能够掌握模型的优化方法和评价指标； 总结  报告要求 给定mnist手写数字图像数据库，自行下载训练集和测试集。要求如下：
 对于测试集数据，完成分类预测，实验精度达到98%以上。 给出每个神经网络层的物理解释，阐述其表征意义。 绘制程序流程图（要求用visio制图） 源代码及必要注释 总结  程序流程图 读取MINST数据集 这里直接使用tensorflow的api来读取，tensorflow.keras.datasets.mnist是一个用来读取minist数据集的模块，调用时它会自动从https://storage.googleapis.com/tensorflow/tf-keras-datasets/minist.npz下载文件,.npz文件里保存了多个numpy数组。可以用numpy.load()读取，tensorflow直接用minist.load_data()完成这个过程。 读取出来的训练集形状为(60000,28,28),即有60000张$(28 \times 28)$的图片，每一位的数据是0-255的整数，训练集标签形状为(60000,),每一位的数据是0-9的整数,为与训练集数据对应的60000个标签。测试集里数据量为10000,其它方面与训练集相同。 读取代码如下：
minist=tf.keras.datasets.mnist (x_train,y_train),(x_test,y_test)=minist.load_data() 训练集中前十张图片如下： 它们对应的标签如下：
[5 0 4 1 9 2 1 3 1 4] 数据处理 处理目标是将图像数据转化为网络所要求的形状，将每一位的值缩放到[0,1]的区间，并将分类标签变为one-hot编码的形式。 首先要将数据从uint8形式转换到float32形式，再将其除以255，由于numpy的广播机制，矩阵中的每一个数据都会被除以255。然后将表示图像的维度展平，代码如下：
x_train=x_train.astype(np.float32) x_test=x_test.astype(np.float32) x_train=x_train.reshape(-1,28*28)/255 x_test=x_test.reshape(-1,28*28)/255 转化后训练集第一张图部分数据如下图：
接下来将标签变为one-hot形式： 只要利用tensorflow.one_hot就可以方便的将标签转为one_hot编码：
y_train_onehot=tf.one_hot(y_train,10) y_test_onehot=tf.one_hot(y_test,10) 转换后的前十个标签如下：
tf.Tensor( [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] [1. 0. 0. 0. 0. 0. 0. 0. 0.</description>
    </item>
    
  </channel>
</rss>
